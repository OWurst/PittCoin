{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8002685,"sourceType":"datasetVersion","datasetId":4712805},{"sourceId":8023344,"sourceType":"datasetVersion","datasetId":4728116}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Start by installing all requirements","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -r /kaggle/input/requirements/requirements.txt\n!pip install scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:04:31.808281Z","iopub.execute_input":"2024-04-04T15:04:31.808701Z","iopub.status.idle":"2024-04-04T15:05:07.906917Z","shell.execute_reply.started":"2024-04-04T15:04:31.808661Z","shell.execute_reply":"2024-04-04T15:05:07.905683Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirements/requirements.txt (line 1)) (2.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirements/requirements.txt (line 2)) (1.26.4)\nCollecting langdetect (from -r /kaggle/input/requirements/requirements.txt (line 3))\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirements/requirements.txt (line 4)) (0.28.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirements/requirements.txt (line 5)) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirements/requirements.txt (line 6)) (4.38.2)\nCollecting seqeval (from -r /kaggle/input/requirements/requirements.txt (line 7))\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirements/requirements.txt (line 8)) (2.1.0)\nCollecting evaluate (from -r /kaggle/input/requirements/requirements.txt (line 9))\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirements/requirements.txt (line 10)) (1.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r /kaggle/input/requirements/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r /kaggle/input/requirements/requirements.txt (line 1)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r /kaggle/input/requirements/requirements.txt (line 1)) (2023.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect->-r /kaggle/input/requirements/requirements.txt (line 3)) (1.16.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r /kaggle/input/requirements/requirements.txt (line 4)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r /kaggle/input/requirements/requirements.txt (line 4)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->-r /kaggle/input/requirements/requirements.txt (line 4)) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate->-r /kaggle/input/requirements/requirements.txt (line 4)) (0.21.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r /kaggle/input/requirements/requirements.txt (line 4)) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (2024.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (0.15.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (4.66.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (3.9.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (0.18.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r /kaggle/input/requirements/requirements.txt (line 10)) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r /kaggle/input/requirements/requirements.txt (line 10)) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r /kaggle/input/requirements/requirements.txt (line 10)) (3.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r /kaggle/input/requirements/requirements.txt (line 8)) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate->-r /kaggle/input/requirements/requirements.txt (line 4)) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r /kaggle/input/requirements/requirements.txt (line 6)) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r /kaggle/input/requirements/requirements.txt (line 5)) (1.3.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: langdetect, seqeval\n  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=39f3297d6f7eff929337fcb07c682c845690e32ecfdf0a542e52f2716c126ff1\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=e269c1446a2bc2bfbc1483d4497863936f47fc88c9a29cb4314b53169d3dd3b8\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built langdetect seqeval\nInstalling collected packages: langdetect, seqeval, evaluate\nSuccessfully installed evaluate-0.4.1 langdetect-1.0.9 seqeval-1.2.2\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next create a function for reading in csvs","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# read in train, dev, test data\ntrain_data = pd.read_csv(\"/kaggle/input/credibility-data/full_data_train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/credibility-data/full_data_test.csv\")\ndev_data = pd.read_csv(\"/kaggle/input/credibility-data/full_data_dev.csv\")\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:05:16.366600Z","iopub.execute_input":"2024-04-04T15:05:16.366976Z","iopub.status.idle":"2024-04-04T15:05:18.764810Z","shell.execute_reply.started":"2024-04-04T15:05:16.366944Z","shell.execute_reply":"2024-04-04T15:05:18.763682Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0  'protests in paris ahead of putin visit to fre...   \n1    'donald trump gives $10,000 to pastor's family'   \n2  'california democrats propose in-state tuition...   \n3       'inner earth glows like in the movie avatar'   \n4  'clinton foundation ceo goes missing after tru...   \n\n                                                text  label  \n0  'paris (ap)  -   human rights activists are ga...      1  \n1  'chilling: what netanyahu is bracing for obama...      0  \n2  'california democrats have proposed a law to g...      1  \n3  'can there be light below the surface of the e...      0  \n4  ' another astonishing security council (sc) re...      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>'protests in paris ahead of putin visit to fre...</td>\n      <td>'paris (ap)  -   human rights activists are ga...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>'donald trump gives $10,000 to pastor's family'</td>\n      <td>'chilling: what netanyahu is bracing for obama...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>'california democrats propose in-state tuition...</td>\n      <td>'california democrats have proposed a law to g...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>'inner earth glows like in the movie avatar'</td>\n      <td>'can there be light below the surface of the e...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>'clinton foundation ceo goes missing after tru...</td>\n      <td>' another astonishing security council (sc) re...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.nn import functional as F\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:05:23.668480Z","iopub.execute_input":"2024-04-04T15:05:23.668878Z","iopub.status.idle":"2024-04-04T15:05:23.674730Z","shell.execute_reply.started":"2024-04-04T15:05:23.668847Z","shell.execute_reply":"2024-04-04T15:05:23.673688Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:05:37.028954Z","iopub.execute_input":"2024-04-04T15:05:37.029323Z","iopub.status.idle":"2024-04-04T15:05:39.875771Z","shell.execute_reply.started":"2024-04-04T15:05:37.029295Z","shell.execute_reply":"2024-04-04T15:05:39.874877Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0569f988bf94eb89de26f72e2c89b69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab40cb14134d4fb4b3da8b493b4114f1"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d241a1c02d4410685585f4517245242"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"561f9dcb5c564a74894ce8a55b7b8716"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2afe737e4d8c40d5bb937924b88a54ae"}},"metadata":{}}]},{"cell_type":"code","source":"# create concatenated df\ntrain_df = train_data\ntrain_df[\"text\"] = tokenizer.cls_token + train_df['title'] + tokenizer.sep_token + train_df['text'] + tokenizer.sep_token\ntrain_df = train_df.drop(['title'], axis=1)\n\ndev_df = dev_data\ndev_df[\"text\"] = tokenizer.cls_token + dev_df['title'] + tokenizer.sep_token + dev_df['text'] + tokenizer.sep_token\ndev_df = dev_df.drop(['title'], axis=1)\n\ntest_df = test_data\ntest_df[\"text\"] = tokenizer.cls_token + test_df['title'] + tokenizer.sep_token + test_df['text'] + tokenizer.sep_token\ntest_df = test_df.drop(['title'], axis=1)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:05:43.846830Z","iopub.execute_input":"2024-04-04T15:05:43.847214Z","iopub.status.idle":"2024-04-04T15:05:44.027382Z","shell.execute_reply.started":"2024-04-04T15:05:43.847181Z","shell.execute_reply":"2024-04-04T15:05:44.026148Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  [CLS]'protests in paris ahead of putin visit t...      1\n1  [CLS]'donald trump gives $10,000 to pastor's f...      0\n2  [CLS]'california democrats propose in-state tu...      1\n3  [CLS]'inner earth glows like in the movie avat...      0\n4  [CLS]'clinton foundation ceo goes missing afte...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS]'protests in paris ahead of putin visit t...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS]'donald trump gives $10,000 to pastor's f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[CLS]'california democrats propose in-state tu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[CLS]'inner earth glows like in the movie avat...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[CLS]'clinton foundation ceo goes missing afte...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef get_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    \n    # Calculate metrics using scikit-learn\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, average='weighted')\n    recall = recall_score(labels, preds, average='weighted')\n    f1 = f1_score(labels, preds, average='weighted')\n\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:05:54.541647Z","iopub.execute_input":"2024-04-04T15:05:54.542003Z","iopub.status.idle":"2024-04-04T15:05:54.548964Z","shell.execute_reply.started":"2024-04-04T15:05:54.541974Z","shell.execute_reply":"2024-04-04T15:05:54.547873Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data.iloc[idx]['text']\n        label = self.data.iloc[idx]['label']\n\n        # Tokenize text\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        input_ids = encoding['input_ids'].squeeze(0)\n        attention_mask = encoding['attention_mask'].squeeze(0)\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'label': torch.tensor(label, dtype=torch.long)\n        }\ntrain_dataset = CustomDataset(train_df, tokenizer, 512)\ndev_dataset = CustomDataset(dev_df, tokenizer, 512)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:14:53.126609Z","iopub.execute_input":"2024-04-04T15:14:53.127067Z","iopub.status.idle":"2024-04-04T15:14:53.137158Z","shell.execute_reply.started":"2024-04-04T15:14:53.127036Z","shell.execute_reply":"2024-04-04T15:14:53.136085Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nimport os\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working/models',          # output directory\n    num_train_epochs=3,              # total number of training epochs\n    per_device_train_batch_size=16,  # batch size per device during training\n    per_device_eval_batch_size=64,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='/kaggle/working/logs',            # directory for storing\n    logging_steps=10,                # log training loss every n steps\n    evaluation_strategy=\"epoch\",     # evaluate model at the end of each epoch\n    save_strategy=\"epoch\",             # save model checkpoint at the end of each epoch\n    save_total_limit=3,              # Limit the total number of saved models\n    save_steps=500,\n)\n\ncredibility_trainer = Trainer(\n    model=model,                     # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,              # training arguments\n    train_dataset=train_dataset,     # training dataset\n    eval_dataset=dev_dataset,        # evaluation dataset\n    tokenizer=tokenizer,             # tokenizer for encoding input data\n    compute_metrics=get_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:14:56.603386Z","iopub.execute_input":"2024-04-04T15:14:56.603786Z","iopub.status.idle":"2024-04-04T15:14:56.622320Z","shell.execute_reply.started":"2024-04-04T15:14:56.603754Z","shell.execute_reply":"2024-04-04T15:14:56.621026Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(dev_df.shape)\n\ntext = tokenizer.cls_token + \"this needs to be tokenized\" + tokenizer.sep_token\ntokenizer.encode(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T00:23:01.745698Z","iopub.execute_input":"2024-04-04T00:23:01.746398Z","iopub.status.idle":"2024-04-04T00:23:01.754410Z","shell.execute_reply.started":"2024-04-04T00:23:01.746369Z","shell.execute_reply":"2024-04-04T00:23:01.753619Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(15726, 2)\n(1966, 2)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[101, 101, 2023, 3791, 2000, 2022, 19204, 3550, 102, 102]"},"metadata":{}}]},{"cell_type":"code","source":"credibility_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:15:21.419104Z","iopub.execute_input":"2024-04-04T15:15:21.419519Z","iopub.status.idle":"2024-04-04T16:08:32.169805Z","shell.execute_reply.started":"2024-04-04T15:15:21.419487Z","shell.execute_reply":"2024-04-04T16:08:32.168847Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2949' max='2949' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2949/2949 53:07, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.039000</td>\n      <td>0.024327</td>\n      <td>0.988301</td>\n      <td>0.988596</td>\n      <td>0.988301</td>\n      <td>0.988312</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.021900</td>\n      <td>0.019157</td>\n      <td>0.992370</td>\n      <td>0.992379</td>\n      <td>0.992370</td>\n      <td>0.992368</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.045700</td>\n      <td>0.025318</td>\n      <td>0.992370</td>\n      <td>0.992387</td>\n      <td>0.992370</td>\n      <td>0.992372</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2949, training_loss=0.0539198517416853, metrics={'train_runtime': 3190.3896, 'train_samples_per_second': 14.788, 'train_steps_per_second': 0.924, 'total_flos': 6249546933792768.0, 'train_loss': 0.0539198517416853, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# save model\nmodel_path = \"/kaggle/working/results\"\nos.makedirs(model_path, exist_ok=True)\n\nmodel_file = os.path.join(model_path, \"model.pth\")\ntorch.save(model.state_dict(), model_file)\n\ntokenizer_file = os.path.join(model_path, \"tokenizer.json\")\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T01:49:54.063257Z","iopub.execute_input":"2024-04-04T01:49:54.063663Z","iopub.status.idle":"2024-04-04T01:49:54.460946Z","shell.execute_reply.started":"2024-04-04T01:49:54.063632Z","shell.execute_reply":"2024-04-04T01:49:54.459966Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/results/tokenizer_config.json',\n '/kaggle/working/results/special_tokens_map.json',\n '/kaggle/working/results/vocab.txt',\n '/kaggle/working/results/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"# load model\nbert_model = DistilBertForSequenceClassification.from_pretrained(\"/kaggle/working/results/model.pth\")\npretrained_tokenizer = DistilBertTokenizer.from_pretrained(\"/kaggle/working/results/\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T15:15:13.257773Z","iopub.execute_input":"2024-04-04T15:15:13.258143Z","iopub.status.idle":"2024-04-04T15:15:14.571998Z","shell.execute_reply.started":"2024-04-04T15:15:13.258113Z","shell.execute_reply":"2024-04-04T15:15:14.570570Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/working/results/model.pth'. Use `repo_type` argument if needed.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mDistilBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/results/model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pretrained_tokenizer \u001b[38;5;241m=\u001b[39m DistilBertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/results/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2874\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2873\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 2874\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2884\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2885\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2886\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2887\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2888\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2889\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2890\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:462\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    464\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/kaggle/working/results/model.pth'. Please provide either the path to a local folder or the repo_id of a model on the Hub."],"ename":"OSError","evalue":"Incorrect path_or_model_id: '/kaggle/working/results/model.pth'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","output_type":"error"}]},{"cell_type":"code","source":"output_dir = '/kaggle/working/results'\ntext_content = \"This is a test file.\"\n\n# Create a new text file and write content into it\nwith open(output_dir + '/test_file.txt', 'w') as f:\n    f.write(text_content)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-04T01:57:47.511601Z","iopub.execute_input":"2024-04-04T01:57:47.512293Z","iopub.status.idle":"2024-04-04T01:57:47.517307Z","shell.execute_reply.started":"2024-04-04T01:57:47.512260Z","shell.execute_reply":"2024-04-04T01:57:47.516287Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"if os.path.exists('/kaggle/working/results/model.pth'):\n    print(\"Model file exists.\")\nelse:\n    print(\"Model file does not exist.\")\n    \nmodel_checkpoint = \"/kaggle/working/models/checkpoint-1.pth\"\n\nif os.path.exists(model_checkpoint):\n    print(\"Model file exists.\")\nelse:\n    print(\"Model file does not exist.\")\n    \nimport os\n\n# Define the directory path\ndirectory = '/kaggle/working/models/checkpoint-2949'\n\n# List the files in the directory\nfiles = os.listdir(directory)\n\n# Print the list of files\nprint(\"Directory contents:\")\nfor file in files:\n    print(file)\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:25:17.304518Z","iopub.execute_input":"2024-04-04T16:25:17.304936Z","iopub.status.idle":"2024-04-04T16:25:17.313206Z","shell.execute_reply.started":"2024-04-04T16:25:17.304905Z","shell.execute_reply":"2024-04-04T16:25:17.312172Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Model file exists.\nModel file does not exist.\nDirectory contents:\ntokenizer_config.json\ntrainer_state.json\ntraining_args.bin\nmodel.safetensors\nvocab.txt\nspecial_tokens_map.json\noptimizer.pt\nscheduler.pt\nconfig.json\nrng_state.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nimport os\n\n# Path to the checkpoint file\ncheckpoint_path = \"/kaggle/working/models/checkpoint-2949\"\n\n# Destination path for the saved checkpoint file\ndestination_path = \"/kaggle/working/models/saved_model.pth\"\n\n# Check if the checkpoint file exists\nif os.path.exists(checkpoint_path):\n    # Copy the checkpoint file to the destination path\n    shutil.copyfile(checkpoint_path, destination_path)\n    print(\"Checkpoint file saved as:\", destination_path)\nelse:\n    print(\"Checkpoint file does not exist.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:38.381025Z","iopub.execute_input":"2024-04-04T16:24:38.381408Z","iopub.status.idle":"2024-04-04T16:24:38.591501Z","shell.execute_reply.started":"2024-04-04T16:24:38.381377Z","shell.execute_reply":"2024-04-04T16:24:38.590266Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check if the checkpoint file exists\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_path):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Copy the checkpoint file to the destination path\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint file saved as:\u001b[39m\u001b[38;5;124m\"\u001b[39m, destination_path)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/kaggle/working/models/checkpoint-2949'"],"ename":"IsADirectoryError","evalue":"[Errno 21] Is a directory: '/kaggle/working/models/checkpoint-2949'","output_type":"error"}]},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Replace 'model_file.bin' with the actual name of your model file\nmodel_file_path = '/kaggle/working/results/model.pth'\n\n# Create a link to download the model file\nFileLink(model_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T01:59:26.232666Z","iopub.execute_input":"2024-04-04T01:59:26.233050Z","iopub.status.idle":"2024-04-04T01:59:26.239951Z","shell.execute_reply.started":"2024-04-04T01:59:26.233020Z","shell.execute_reply":"2024-04-04T01:59:26.239002Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/results/model.pth","text/html":"<a href='/kaggle/working/results/model.pth' target='_blank'>/kaggle/working/results/model.pth</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = CustomDataset(test_df, tokenizer, 512)\n\nresults = credibility_trainer.evaluate(eval_dataset=test_dataset)\n\nresults_df = pd.DataFrame(results, index=[0])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:12:44.021207Z","iopub.execute_input":"2024-04-04T16:12:44.022064Z","iopub.status.idle":"2024-04-04T16:14:11.151519Z","shell.execute_reply.started":"2024-04-04T16:12:44.022017Z","shell.execute_reply":"2024-04-04T16:14:11.150435Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='46' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [31/31 18:32]\n    </div>\n    "},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   eval_loss  eval_accuracy  eval_precision  eval_recall  eval_f1  \\\n0   0.037339       0.991349        0.991355     0.991349  0.99135   \n\n   eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch  \n0       87.1101                   22.558                  0.356    3.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eval_loss</th>\n      <th>eval_accuracy</th>\n      <th>eval_precision</th>\n      <th>eval_recall</th>\n      <th>eval_f1</th>\n      <th>eval_runtime</th>\n      <th>eval_samples_per_second</th>\n      <th>eval_steps_per_second</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.037339</td>\n      <td>0.991349</td>\n      <td>0.991355</td>\n      <td>0.991349</td>\n      <td>0.99135</td>\n      <td>87.1101</td>\n      <td>22.558</td>\n      <td>0.356</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Recreate the model architecture\n\n# Load the trained weights from the checkpoint file\ncheckpoint_path = \"/kaggle/working/models/checkpoint-2949\"\n#model.load_state_dict(torch.load(os.path.join(checkpoint_path, \"model.safetensors\")))\nmodel = DistilBertForSequenceClassification.from_pretrained(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:31:40.010324Z","iopub.execute_input":"2024-04-04T16:31:40.011448Z","iopub.status.idle":"2024-04-04T16:31:40.123281Z","shell.execute_reply.started":"2024-04-04T16:31:40.011414Z","shell.execute_reply":"2024-04-04T16:31:40.122351Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Instantiate Trainer with the trained model and evaluation arguments\ntrainer = Trainer(\n    model=model,  # The trained model\n    tokenizer=tokenizer,  # The tokenizer associated with the model\n    compute_metrics=get_metrics,  # Function to compute evaluation metrics\n)\n\n# Evaluate the model\nresults = trainer.evaluate(test_dataset)\n\n# Print the evaluation results\nresults_df = pd.DataFrame(results, index=[0])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:38:00.853557Z","iopub.execute_input":"2024-04-04T16:38:00.853940Z","iopub.status.idle":"2024-04-04T16:39:27.157162Z","shell.execute_reply.started":"2024-04-04T16:38:00.853910Z","shell.execute_reply":"2024-04-04T16:39:27.156089Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='246' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [246/246 01:25]\n    </div>\n    "},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   eval_loss  eval_accuracy  eval_precision  eval_recall  eval_f1  \\\n0   0.037339       0.991349        0.991355     0.991349  0.99135   \n\n   eval_runtime  eval_samples_per_second  eval_steps_per_second  \n0       86.2748                   22.776                  2.851  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eval_loss</th>\n      <th>eval_accuracy</th>\n      <th>eval_precision</th>\n      <th>eval_recall</th>\n      <th>eval_f1</th>\n      <th>eval_runtime</th>\n      <th>eval_samples_per_second</th>\n      <th>eval_steps_per_second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.037339</td>\n      <td>0.991349</td>\n      <td>0.991355</td>\n      <td>0.991349</td>\n      <td>0.99135</td>\n      <td>86.2748</td>\n      <td>22.776</td>\n      <td>2.851</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to get predicted probabilities for all elements in the dataset\ndef get_predicted_probabilities(dataset):\n    # Initialize list to store predicted probabilities\n    all_predicted_probabilities = []\n    \n    # Iterate over each element in the dataset\n    for i in range(len(dataset)):\n        # Get the input_ids and attention_mask from the dataset\n        input_ids = dataset[i]['input_ids']\n        attention_mask = dataset[i]['attention_mask']\n        \n        # Perform inference\n        with torch.no_grad():\n            outputs = model(input_ids=input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0))\n        \n        # Get predicted probabilities\n        predicted_probabilities = torch.softmax(outputs.logits, dim=1)\n        \n        # Append predicted probabilities to the list\n        all_predicted_probabilities.append(predicted_probabilities.numpy()[0].tolist())\n    \n    return all_predicted_probabilities\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Get predicted probabilities for all elements in the dataset\npredicted_probabilities = get_predicted_probabilities(test_dataset)\n\n# Print the predicted probabilities\nprint(predicted_probabilities)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:44:02.126546Z","iopub.execute_input":"2024-04-04T16:44:02.126920Z","iopub.status.idle":"2024-04-04T16:44:02.563741Z","shell.execute_reply.started":"2024-04-04T16:44:02.126892Z","shell.execute_reply":"2024-04-04T16:44:02.562223Z"},"trusted":true},"execution_count":34,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Get predicted probabilities for all elements in the dataset\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m predicted_probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mget_predicted_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Print the predicted probabilities\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_probabilities)\n","Cell \u001b[0;32mIn[34], line 14\u001b[0m, in \u001b[0;36mget_predicted_probabilities\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get predicted probabilities\u001b[39;00m\n\u001b[1;32m     17\u001b[0m predicted_probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:1002\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1002\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:814\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    812\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 814\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    817\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:141\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03membeddings)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     input_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    143\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# isues similar to issue #5664\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"],"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)","output_type":"error"}]},{"cell_type":"code","source":"import shutil\n\n# Define the directory path\ndirectory_path = '/kaggle/working/models/checkpoint-2949'\n\n# Define the output zip file path\nzip_file_path = '/kaggle/working/models/checkpoint-2949.zip'\n\n# Create a zip file containing the contents of the directory\nshutil.make_archive(zip_file_path.split('.zip')[0], 'zip', directory_path)\n\n# Provide a download link to the zip file\nprint(f'Download the zip file containing the directory contents: [{zip_file_path}]({zip_file_path})')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:45:34.407230Z","iopub.execute_input":"2024-04-04T16:45:34.407582Z","iopub.status.idle":"2024-04-04T16:46:21.551600Z","shell.execute_reply.started":"2024-04-04T16:45:34.407555Z","shell.execute_reply":"2024-04-04T16:46:21.550551Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Download the zip file containing the directory contents: [/kaggle/working/models/checkpoint-2949.zip](/kaggle/working/models/checkpoint-2949.zip)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Provide a download link to the zip file\nFileLink(\"/kaggle/working/models/checkpoint-2949.zip\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:47:31.794120Z","iopub.execute_input":"2024-04-04T16:47:31.794490Z","iopub.status.idle":"2024-04-04T16:47:31.801900Z","shell.execute_reply.started":"2024-04-04T16:47:31.794465Z","shell.execute_reply":"2024-04-04T16:47:31.800403Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/models/checkpoint-2949.zip","text/html":"<a href='/kaggle/working/models/checkpoint-2949.zip' target='_blank'>/kaggle/working/models/checkpoint-2949.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import HTML\n\n# Create a download link\nHTML(f'<a href=\"/kaggle/working/models/checkpoint-2949.zip\" download>Click here to download the zip file</a>')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:49:54.206709Z","iopub.execute_input":"2024-04-04T16:49:54.207645Z","iopub.status.idle":"2024-04-04T16:49:54.213610Z","shell.execute_reply.started":"2024-04-04T16:49:54.207590Z","shell.execute_reply":"2024-04-04T16:49:54.212685Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a href=\"/kaggle/working/models/checkpoint-2949.zip\" download>Click here to download the zip file</a>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the directory path\ndirectory = '/kaggle/working/models/checkpoint-2949'\n\n# Define the output zip file path\nzip_file_path = '/kaggle/working/checkpoint-2949.zip'\n\n# Create a zip file of the directory contents\nshutil.make_archive('/kaggle/working/checkpoint-2949', 'zip', directory)\n\n# Create a download link\nHTML(f'<a href=\"{zip_file_path}\" download>Click here to download the zip file</a>')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:50:48.846981Z","iopub.execute_input":"2024-04-04T16:50:48.847348Z","iopub.status.idle":"2024-04-04T16:51:34.198081Z","shell.execute_reply.started":"2024-04-04T16:50:48.847319Z","shell.execute_reply":"2024-04-04T16:51:34.197014Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a href=\"/kaggle/working/checkpoint-2949.zip\" download>Click here to download the zip file</a>"},"metadata":{}}]},{"cell_type":"code","source":"if os.path.exists(zip_file_path):\n    print(\"Model file exists.\")\nelse:\n    print(\"Model file does not exist.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:54:17.441840Z","iopub.execute_input":"2024-04-04T16:54:17.442716Z","iopub.status.idle":"2024-04-04T16:54:17.447646Z","shell.execute_reply.started":"2024-04-04T16:54:17.442683Z","shell.execute_reply":"2024-04-04T16:54:17.446592Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Model file exists.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"FileLink(zip_file_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:55:23.418629Z","iopub.execute_input":"2024-04-04T16:55:23.419378Z","iopub.status.idle":"2024-04-04T16:55:23.425624Z","shell.execute_reply.started":"2024-04-04T16:55:23.419343Z","shell.execute_reply":"2024-04-04T16:55:23.424682Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/checkpoint-2949.zip","text/html":"<a href='/kaggle/working/checkpoint-2949.zip' target='_blank'>/kaggle/working/checkpoint-2949.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"FileLink(zip_file_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:55:43.066005Z","iopub.execute_input":"2024-04-04T16:55:43.066374Z","iopub.status.idle":"2024-04-04T16:55:43.073421Z","shell.execute_reply.started":"2024-04-04T16:55:43.066342Z","shell.execute_reply":"2024-04-04T16:55:43.072218Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/checkpoint-2949.zip","text/html":"<a href='/kaggle/working/checkpoint-2949.zip' target='_blank'>/kaggle/working/checkpoint-2949.zip</a><br>"},"metadata":{}}]}]}